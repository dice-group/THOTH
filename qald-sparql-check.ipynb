{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all QALD-8 Queries\n",
    "# For each question\n",
    "    # Extract all URIs\n",
    "    # Find sameAs links to DE, FR, ES dbpedia\n",
    "    # If links exist in same language for all URIs then;\n",
    "        # generate sparql for all languages\n",
    "        # write the sparql like: \"query_<language-abbr>\": { \"sparql\": <sparql> }\n",
    "# Store the new QALD File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qald-7-train-multilingual\n"
     ]
    }
   ],
   "source": [
    "# Load QALD8 questions\n",
    "\n",
    "# import urllib library\n",
    "from urllib.request import urlopen\n",
    "  \n",
    "# import json\n",
    "import json\n",
    "# store the URL in url as \n",
    "# parameter for urlopen\n",
    "url = \"https://raw.githubusercontent.com/ag-sc/QALD/master/7/data/qald-7-train-multilingual.json\"\n",
    "  \n",
    "# store the response of URL\n",
    "response = urlopen(url)\n",
    "  \n",
    "# storing the JSON response \n",
    "# from url in data\n",
    "data_json = json.loads(response.read())\n",
    "  \n",
    "# print the json response\n",
    "print(data_json['dataset']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from string import Template\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "# Choosing to fetch only one link\n",
    "sparql_template = 'SELECT ?l WHERE { <$uri> owl:sameAs ?l . FILTER(regex(str(?l), \"http://$lang.dbpedia.org/\" )) }'\n",
    "sparql_template2 = 'SELECT ?l WHERE { <$uri> owl:sameAs ?l . FILTER(regex(str(?l), \"http://$lang.dbpedia.org/\" )) } LIMIT 1'\n",
    "def fetch_links(uri, lang):\n",
    "    links_set = set()\n",
    "    # form the sparql\n",
    "    query = Template(sparql_template).substitute(uri=uri, lang=lang)\n",
    "    # query\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    #print('Result size:',len(results[\"results\"][\"bindings\"]))\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        links_set.add(result['l']['value'])\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "    return links_set\n",
    "\n",
    "def fetch_single_link(uri, lang):\n",
    "    single_link = None\n",
    "    # form the sparql\n",
    "    query = Template(sparql_template2).substitute(uri=uri, lang=lang)\n",
    "    # query\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    #print(results)\n",
    "    #print('Result size:',len(results[\"results\"][\"bindings\"]))\n",
    "\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        single_link = result['l']['value']\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "    return single_link\n",
    "\n",
    "# function to check and return links for URIs in a given language\n",
    "def check_links(uri_list, lang):\n",
    "    missing_links = False\n",
    "    # For each uri look for language specific links\n",
    "    link_map = {}\n",
    "    for uri in uri_list:\n",
    "        links_set = fetch_links(uri, lang)\n",
    "        if len(links_set) == 0:\n",
    "            missing_links = True\n",
    "        link_map[uri] = links_set\n",
    "    return (missing_links, link_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, {'http://dbpedia.org/resource/Colombo_Lighthouse': set(), 'http://dbpedia.org/resource/Donald_Trump': {'http://fr.dbpedia.org/resource/Donald_Trump'}})\n"
     ]
    }
   ],
   "source": [
    "# Test Block\n",
    "print(check_links({'http://dbpedia.org/resource/Colombo_Lighthouse','http://dbpedia.org/resource/Donald_Trump'},'fr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_dict = { 'de': 'http://de.dbpedia.org/sparql', 'es': 'https://es.dbpedia.org/sparql', 'fr': 'http://fr.dbpedia.org/sparql'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SPARQL\n",
    "def convert_sparql(sparql_str, prefix_mentions, uris, lang):\n",
    "    link_map = {}\n",
    "    # fetch the links for tuples\n",
    "    for entry in prefix_mentions.keys():\n",
    "        id = entry\n",
    "        uri = prefix_mentions[entry]\n",
    "        single_link = fetch_single_link(uri, lang)\n",
    "        #print(single_link)\n",
    "        if single_link:\n",
    "            link_map[id] = single_link\n",
    "    # fetch the links for uris\n",
    "    for uri in uris:\n",
    "        single_link = fetch_single_link(uri, lang)\n",
    "        if single_link:\n",
    "            link_map[uri] = single_link\n",
    "    #print('link map', link_map)\n",
    "    if len(link_map) == 0:\n",
    "        return None\n",
    "    # create sparql\n",
    "    rep = dict((re.escape(k), v) for k, v in link_map.items()) \n",
    "    pattern = re.compile(\"|\".join(rep.keys()))\n",
    "    sparql_str = pattern.sub(lambda m: rep[re.escape(m.group(0))], sparql_str)\n",
    "    # return the sparql\n",
    "    return sparql_str\n",
    "def get_all_sparql(sparql_str, prefix_mentions, uris):\n",
    "    sparql_map = {}\n",
    "    # for each language fetch the sparql queries\n",
    "    for lang in endpoint_dict.keys():\n",
    "        sparql_map[lang] = convert_sparql(sparql_str, prefix_mentions, uris, lang)\n",
    "    # return the queries\n",
    "    return sparql_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1 / 215 \n",
      "Progress: 2 / 215 \n",
      "Progress: 3 / 215 \n",
      "Progress: 4 / 215 \n",
      "Progress: 5 / 215 \n",
      "Progress: 6 / 215 \n",
      "Progress: 7 / 215 \n",
      "Progress: 8 / 215 \n",
      "Progress: 9 / 215 \n",
      "Progress: 10 / 215 \n",
      "Progress: 11 / 215 \n",
      "Progress: 12 / 215 \n",
      "Progress: 13 / 215 \n",
      "Progress: 14 / 215 \n",
      "Progress: 15 / 215 \n",
      "Progress: 16 / 215 \n",
      "Progress: 17 / 215 \n",
      "Progress: 18 / 215 \n",
      "Progress: 19 / 215 \n",
      "Progress: 20 / 215 \n",
      "Progress: 21 / 215 \n",
      "Progress: 22 / 215 \n",
      "Progress: 23 / 215 \n",
      "Progress: 24 / 215 \n",
      "Progress: 25 / 215 \n",
      "Progress: 26 / 215 \n",
      "Progress: 27 / 215 \n",
      "Progress: 28 / 215 \n",
      "Progress: 29 / 215 \n",
      "Progress: 30 / 215 \n",
      "Progress: 31 / 215 \n",
      "Progress: 32 / 215 \n",
      "Progress: 33 / 215 \n",
      "Progress: 34 / 215 \n",
      "Progress: 35 / 215 \n",
      "Progress: 36 / 215 \n",
      "Progress: 37 / 215 \n",
      "Progress: 38 / 215 \n",
      "Progress: 39 / 215 \n",
      "Progress: 40 / 215 \n",
      "Progress: 41 / 215 \n",
      "Progress: 42 / 215 \n",
      "Progress: 43 / 215 \n",
      "Progress: 44 / 215 \n",
      "Progress: 45 / 215 \n",
      "Progress: 46 / 215 \n",
      "Progress: 47 / 215 \n",
      "Progress: 48 / 215 \n",
      "Progress: 49 / 215 \n",
      "Progress: 50 / 215 \n",
      "Progress: 51 / 215 \n",
      "Progress: 52 / 215 \n",
      "Progress: 53 / 215 \n",
      "Progress: 54 / 215 \n",
      "Progress: 55 / 215 \n",
      "Progress: 56 / 215 \n",
      "Progress: 57 / 215 \n",
      "Progress: 58 / 215 \n",
      "Progress: 59 / 215 \n",
      "Progress: 60 / 215 \n",
      "Progress: 61 / 215 \n",
      "Progress: 62 / 215 \n",
      "Progress: 63 / 215 \n",
      "Progress: 64 / 215 \n",
      "Progress: 65 / 215 \n",
      "Progress: 66 / 215 \n",
      "Progress: 67 / 215 \n",
      "Progress: 68 / 215 \n",
      "Progress: 69 / 215 \n",
      "Progress: 70 / 215 \n",
      "Progress: 71 / 215 \n",
      "Progress: 72 / 215 \n",
      "Progress: 73 / 215 \n",
      "Progress: 74 / 215 \n",
      "Progress: 75 / 215 \n",
      "Progress: 76 / 215 \n",
      "Progress: 77 / 215 \n",
      "Progress: 78 / 215 \n",
      "Progress: 79 / 215 \n",
      "Progress: 80 / 215 \n",
      "Progress: 81 / 215 \n",
      "Progress: 82 / 215 \n",
      "Progress: 83 / 215 \n",
      "Progress: 84 / 215 \n",
      "Progress: 85 / 215 \n",
      "Progress: 86 / 215 \n",
      "Progress: 87 / 215 \n",
      "Progress: 88 / 215 \n",
      "Progress: 89 / 215 \n",
      "Progress: 90 / 215 \n",
      "Progress: 91 / 215 \n",
      "Progress: 92 / 215 \n",
      "Progress: 93 / 215 \n",
      "Progress: 94 / 215 \n",
      "Progress: 95 / 215 \n",
      "Progress: 96 / 215 \n",
      "Progress: 97 / 215 \n",
      "Progress: 98 / 215 \n",
      "Progress: 99 / 215 \n",
      "Progress: 100 / 215 \n",
      "Progress: 101 / 215 \n",
      "Progress: 102 / 215 \n",
      "Progress: 103 / 215 \n",
      "Progress: 104 / 215 \n",
      "Progress: 105 / 215 \n",
      "Progress: 106 / 215 \n",
      "Progress: 107 / 215 \n",
      "Progress: 108 / 215 \n",
      "Progress: 109 / 215 \n",
      "Progress: 110 / 215 \n",
      "Progress: 111 / 215 \n",
      "Progress: 112 / 215 \n",
      "Progress: 113 / 215 \n",
      "Progress: 114 / 215 \n",
      "Progress: 115 / 215 \n",
      "Progress: 116 / 215 \n",
      "Progress: 117 / 215 \n",
      "Progress: 118 / 215 \n",
      "Progress: 119 / 215 \n",
      "Progress: 120 / 215 \n",
      "Progress: 121 / 215 \n",
      "Progress: 122 / 215 \n",
      "Progress: 123 / 215 \n",
      "Progress: 124 / 215 \n",
      "Progress: 125 / 215 \n",
      "Progress: 126 / 215 \n",
      "Progress: 127 / 215 \n",
      "Progress: 128 / 215 \n",
      "Progress: 129 / 215 \n",
      "Progress: 130 / 215 \n",
      "Progress: 131 / 215 \n",
      "Progress: 132 / 215 \n",
      "Progress: 133 / 215 \n",
      "Progress: 134 / 215 \n",
      "Progress: 135 / 215 \n",
      "Progress: 136 / 215 \n",
      "Progress: 137 / 215 \n",
      "Progress: 138 / 215 \n",
      "Progress: 139 / 215 \n",
      "Progress: 140 / 215 \n",
      "Progress: 141 / 215 \n",
      "Progress: 142 / 215 \n",
      "Progress: 143 / 215 \n",
      "Progress: 144 / 215 \n",
      "Progress: 145 / 215 \n",
      "Progress: 146 / 215 \n",
      "Progress: 147 / 215 \n",
      "Progress: 148 / 215 \n",
      "Progress: 149 / 215 \n",
      "Progress: 150 / 215 \n",
      "Progress: 151 / 215 \n",
      "Progress: 152 / 215 \n",
      "Progress: 153 / 215 \n",
      "Progress: 154 / 215 \n",
      "Progress: 155 / 215 \n",
      "Progress: 156 / 215 \n",
      "Progress: 157 / 215 \n",
      "Progress: 158 / 215 \n",
      "Progress: 159 / 215 \n",
      "Progress: 160 / 215 \n",
      "Progress: 161 / 215 \n",
      "Progress: 162 / 215 \n",
      "Progress: 163 / 215 \n",
      "Progress: 164 / 215 \n",
      "Progress: 165 / 215 \n",
      "Progress: 166 / 215 \n",
      "Progress: 167 / 215 \n",
      "Progress: 168 / 215 \n",
      "Progress: 169 / 215 \n",
      "Progress: 170 / 215 \n",
      "Progress: 171 / 215 \n",
      "Progress: 172 / 215 \n",
      "Progress: 173 / 215 \n",
      "Progress: 174 / 215 \n",
      "Progress: 175 / 215 \n",
      "Progress: 176 / 215 \n",
      "Progress: 177 / 215 \n",
      "Progress: 178 / 215 \n",
      "Progress: 179 / 215 \n",
      "Progress: 180 / 215 \n",
      "Progress: 181 / 215 \n",
      "Progress: 182 / 215 \n",
      "Progress: 183 / 215 \n",
      "Progress: 184 / 215 \n",
      "Progress: 185 / 215 \n",
      "Progress: 186 / 215 \n",
      "Progress: 187 / 215 \n",
      "Progress: 188 / 215 \n",
      "Progress: 189 / 215 \n",
      "Progress: 190 / 215 \n",
      "Progress: 191 / 215 \n",
      "Progress: 192 / 215 \n",
      "Progress: 193 / 215 \n",
      "Progress: 194 / 215 \n",
      "Progress: 195 / 215 \n",
      "Progress: 196 / 215 \n",
      "Progress: 197 / 215 \n",
      "Progress: 198 / 215 \n",
      "Progress: 199 / 215 \n",
      "Progress: 200 / 215 \n",
      "Progress: 201 / 215 \n",
      "Progress: 202 / 215 \n",
      "Progress: 203 / 215 \n",
      "Progress: 204 / 215 \n",
      "Progress: 205 / 215 \n",
      "Progress: 206 / 215 \n",
      "Progress: 207 / 215 \n",
      "Progress: 208 / 215 \n",
      "Progress: 209 / 215 \n",
      "Progress: 210 / 215 \n",
      "Progress: 211 / 215 \n",
      "Progress: 212 / 215 \n",
      "Progress: 213 / 215 \n",
      "Progress: 214 / 215 \n",
      "Progress: 215 / 215 \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "prefix_map = {}\n",
    "count = 0\n",
    "total_len = len(data_json['questions'])\n",
    "for question in data_json['questions']:\n",
    "    #sparql_uris = set()\n",
    "    sparql_str = question['query']['sparql']\n",
    "    #print('SPARQL:', sparql_str)\n",
    "    # extract all prefixes to make a map\n",
    "    prefix_tuples=re.findall('PREFIX\\s+([a-zA-Z0-9]+):\\s+<(.*?)>',sparql_str, re.IGNORECASE)\n",
    "    for entry in prefix_tuples:\n",
    "        prefix_map[entry[0]] = entry[1]\n",
    "    #print(prefix_map)\n",
    "    # extract all prefix mentions\n",
    "    prefix_mentions = re.findall('{?[\\s\\t\\n\\r]+([\\w\\d]+):([^<\\s]+)',sparql_str, re.IGNORECASE)\n",
    "    #print(prefix_mentions)\n",
    "    # join the local name with prefix and store it in uri set\n",
    "    abbr_map = {}\n",
    "    for entry in prefix_mentions:\n",
    "        formed_uri = prefix_map[entry[0]]+entry[1]\n",
    "        abbr_map[entry[0]+':'+entry[1]] = formed_uri\n",
    "        #sparql_uris.add(formed_uri)\n",
    "    #print(uris)\n",
    "    # extract all direct uri mentions\n",
    "    extra_uris = re.findall('<(.*?)>',sparql_str, re.IGNORECASE)\n",
    "    #sparql_uris.update(extra_uris)\n",
    "    # Generate and save language specific SPARQL queries\n",
    "    sparql_map = get_all_sparql(sparql_str, abbr_map, extra_uris)\n",
    "    count+= 1\n",
    "    question['query']['translated'] = sparql_map\n",
    "    print('Progress:',count,'/',total_len,'\\r')\n",
    "    # print('Translated SPARQL',sparql_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified QALD JSON written to file.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('porque-test/qald-7-train-multilingual_translated-sparql.json', 'w') as out:\n",
    "    out.write(json.dumps(data_json, indent=4, sort_keys=True))\n",
    "print('Modified QALD JSON written to file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the answers fetched by sparql queries of each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
